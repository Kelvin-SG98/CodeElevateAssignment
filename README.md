# ğŸš— Projeto: AnÃ¡lise de Corridas de Transporte Privado

Este projeto demonstra a aplicaÃ§Ã£o da arquitetura **Medallion** (Bronze â†’ Silver â†’ Gold) com **PySpark** e **Delta Lake** em um ambiente **Databricks** para tratar dados de um aplicativo de transporte privado.

---

## ğŸ“ Estrutura do Projeto

- **Bronze**: IngestÃ£o bruta do arquivo CSV `info_transportes.csv`.
- **Silver**: PadronizaÃ§Ã£o das colunas de data e criaÃ§Ã£o da coluna `DT_REF` (data de referÃªncia).
- **Gold**: AgregaÃ§Ãµes diÃ¡rias com estatÃ­sticas por categoria e propÃ³sito das corridas.

---

## ğŸ§ª Dataset de entrada

Arquivo: `info_transportes.csv`  
Colunas:
- `DATA_INICIO`
- `DATA_FIM`
- `CATEGORIA` (`NegÃ³cio`, `Pessoal`)
- `LOCAL_INICIO`
- `LOCAL_FIM`
- `PROPOSITO`
- `DISTANCIA`

---

## ğŸ“Š MÃ©tricas geradas (Tabela Final: `info_corridas_do_dia`)

| Coluna             | DescriÃ§Ã£o                                                                 |
|--------------------|---------------------------------------------------------------------------|
| `DT_REF`           | Data de referÃªncia no formato `yyyy-MM-dd`                                |
| `QT_CORR`          | Quantidade total de corridas no dia                                       |
| `QT_CORR_NEG`      | Quantidade de corridas com categoria **NegÃ³cio**                          |
| `QT_CORR_PESS`     | Quantidade de corridas com categoria **Pessoal**                          |
| `VL_MAX_DIST`      | Maior distÃ¢ncia registrada em uma corrida no dia                          |
| `VL_MIN_DIST`      | Menor distÃ¢ncia registrada em uma corrida no dia                          |
| `VL_AVG_DIST`      | DistÃ¢ncia mÃ©dia das corridas no dia                                       |
| `QT_CORR_REUNI`    | Quantidade de corridas com propÃ³sito **ReuniÃ£o**                          |
| `QT_CORR_NAO_REUNI`| Quantidade de corridas com propÃ³sito **diferente de ReuniÃ£o**             |

---

## ğŸ› ï¸ Ferramentas utilizadas

- Apache Spark (PySpark)
- Delta Lake
- Databricks Community Edition
- Pandas (para leitura inicial)

---

## ğŸ§  Destaques tÃ©cnicos

- ImplementaÃ§Ã£o com **funÃ§Ãµes reutilizÃ¡veis** para tratamento e transformaÃ§Ã£o
- SeparaÃ§Ã£o clara das camadas do Lakehouse
- Uso de funÃ§Ãµes do Spark SQL para limpeza, parsing e agregaÃ§Ãµes

---

## ğŸ“Œ ExecuÃ§Ã£o

O notebook pode ser executado diretamente no ambiente Databricks.  
Certifique-se de fazer o upload do arquivo `info_transportes.csv` para o DBFS em `/FileStore/`.

---